{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import preprocessing\n",
    "\n",
    "#Visualization Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Sklearn Tools and Modules\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22402, 146)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acquire the Data\n",
    "df = acquire.get_equiprail()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11504, 35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the data\n",
    "df = prepare.prep_equip_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11504 entries, 0 to 11503\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   track_damage      11504 non-null  int64 \n",
      " 1   total_damage      11504 non-null  int64 \n",
      " 2   weather           11504 non-null  int64 \n",
      " 3   equip_damage      11504 non-null  int64 \n",
      " 4   railroad_company  11504 non-null  object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 539.2+ KB\n"
     ]
    }
   ],
   "source": [
    "equip_df = df[['track_damage', 'total_damage', 'weather', 'equip_damage', 'railroad_company']]\n",
    "equip_df.info()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data\n",
    "train, validate, X_train, y_train, X_validate, y_validate, X_test, y_test = preprocessing.train_validate_test(equip_df, 'railroad_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = preprocessing.get_object_cols(equip_df)\n",
    "numeric_cols = preprocessing.get_numeric_X_cols(X_train, object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled, X_validate_scaled, X_test_scaled = preprocessing.min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(X_train, X_validate, X_test, numeric_cols):\n",
    "    '''\n",
    "    this function takes in 3 dataframes with the same columns, \n",
    "    a list of numeric column names (because the scaler can only work with numeric columns),\n",
    "    and fits a min-max scaler to the first dataframe and transforms all\n",
    "    3 dataframes using that scaler. \n",
    "    it returns 3 dataframes with the same column names and scaled values. \n",
    "    '''\n",
    "    # create the scaler object and fit it to X_train (i.e. identify min and max)\n",
    "    # if copy = false, inplace row normalization happens and avoids a copy (if the input is already a numpy array).\n",
    "\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "    #scale X_train, X_validate, X_test using the mins and maxes stored in the scaler derived from X_train. \n",
    "    # \n",
    "    X_train_scaled_array = scaler.transform(X_train[numeric_cols])\n",
    "    X_validate_scaled_array = scaler.transform(X_validate[numeric_cols])\n",
    "    X_test_scaled_array = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # convert arrays to dataframes\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled_array, \n",
    "                                  columns=numeric_cols).\\\n",
    "                                  set_index([X_train.index.values])\n",
    "\n",
    "    X_validate_scaled = pd.DataFrame(X_validate_scaled_array, \n",
    "                                     columns=numeric_cols).\\\n",
    "                                     set_index([X_validate.index.values])\n",
    "\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled_array, \n",
    "                                 columns=numeric_cols).\\\n",
    "                                 set_index([X_test.index.values])\n",
    "\n",
    "    \n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_damage</th>\n",
       "      <th>total_damage</th>\n",
       "      <th>weather</th>\n",
       "      <th>equip_damage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10506</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.071481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10069</th>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.006342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6442 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       track_damage  total_damage  weather  equip_damage\n",
       "8116       0.003655      0.000850      0.0      0.000004\n",
       "2539       0.000005      0.002467      0.0      0.002511\n",
       "10506      0.000033      0.000571      0.2      0.000576\n",
       "6836       0.013576      0.071481      0.0      0.069471\n",
       "7873       0.000033      0.001157      0.2      0.001173\n",
       "...             ...           ...      ...           ...\n",
       "4466       0.001582      0.000807      0.2      0.000451\n",
       "5250       0.002074      0.000910      0.0      0.000439\n",
       "9997       0.005115      0.006726      0.2      0.005633\n",
       "10320      0.000000      0.000887      0.2      0.000905\n",
       "10069      0.010614      0.008701      0.2      0.006342\n",
       "\n",
       "[6442 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UP      4345\n",
       "BNSF    3160\n",
       "NS      1774\n",
       "CSX     1482\n",
       "ATK      743\n",
       "Name: railroad_company, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.railroad_company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 38%\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline Accuracy: {round(max(df.railroad_company.value_counts()) / df.shape[0] *100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       436\n",
      "        BNSF       0.66      0.04      0.07      1769\n",
      "         CSX       0.00      0.00      0.00       851\n",
      "          NS       0.00      0.00      0.00       975\n",
      "          UP       0.38      0.99      0.55      2411\n",
      "\n",
      "    accuracy                           0.38      6442\n",
      "   macro avg       0.21      0.21      0.12      6442\n",
      "weighted avg       0.32      0.38      0.22      6442\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       181\n",
      "        BNSF       0.47      0.02      0.05       748\n",
      "         CSX       0.00      0.00      0.00       339\n",
      "          NS       0.00      0.00      0.00       432\n",
      "          UP       0.38      0.99      0.55      1061\n",
      "\n",
      "    accuracy                           0.39      2761\n",
      "   macro avg       0.17      0.20      0.12      2761\n",
      "weighted avg       0.28      0.39      0.23      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the scaled data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_scaled)\n",
    "test['predicted'] = lm.predict(X_test_scaled)\n",
    "\n",
    "#Review how the lm model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted, zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the lm model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- The LM model does not improve upon the baseline accuracy. 39% on validate.\n",
    "- What does this mean for the features we selected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.99      0.99      0.99       436\n",
      "        BNSF       0.97      1.00      0.99      1769\n",
      "         CSX       1.00      0.99      1.00       851\n",
      "          NS       1.00      0.97      0.99       975\n",
      "          UP       1.00      0.99      1.00      2411\n",
      "\n",
      "    accuracy                           0.99      6442\n",
      "   macro avg       0.99      0.99      0.99      6442\n",
      "weighted avg       0.99      0.99      0.99      6442\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.19      0.14      0.16       181\n",
      "        BNSF       0.35      0.38      0.36       748\n",
      "         CSX       0.20      0.15      0.17       339\n",
      "          NS       0.17      0.13      0.15       432\n",
      "          UP       0.45      0.51      0.48      1061\n",
      "\n",
      "    accuracy                           0.35      2761\n",
      "   macro avg       0.27      0.26      0.26      2761\n",
      "weighted avg       0.33      0.35      0.34      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the KNN object with a k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
    "\n",
    "#Fit the object to the scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_scaled)\n",
    "\n",
    "#Review how the knn model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted,  zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the knn model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "   - Using a K=6 returns the best accuracy score for predicting railroad company. 34% on accuracy.\n",
    "   - Using weights=distance parameter results in overfitting on the train dataset but retains a similar accuracy score on the validate data as the default weights hyperparamter of 'uniform'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.69      0.37      0.48       436\n",
      "        BNSF       0.60      0.66      0.63      1769\n",
      "         CSX       0.76      0.32      0.45       851\n",
      "          NS       0.84      0.19      0.31       975\n",
      "          UP       0.58      0.88      0.70      2411\n",
      "\n",
      "    accuracy                           0.61      6442\n",
      "   macro avg       0.69      0.48      0.51      6442\n",
      "weighted avg       0.66      0.61      0.57      6442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "\n",
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.31      0.14      0.19       181\n",
      "        BNSF       0.36      0.39      0.38       748\n",
      "         CSX       0.36      0.13      0.19       339\n",
      "          NS       0.24      0.04      0.07       432\n",
      "          UP       0.44      0.69      0.54      1061\n",
      "\n",
      "    accuracy                           0.41      2761\n",
      "   macro avg       0.34      0.28      0.27      2761\n",
      "weighted avg       0.37      0.41      0.36      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_scaled)\n",
    "print('----------------')\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "   - Random Forest achieves the highest accuracy score thus far. 42% on validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.59      0.20      0.30       436\n",
      "        BNSF       0.46      0.51      0.48      1769\n",
      "         CSX       0.56      0.30      0.39       851\n",
      "          NS       0.71      0.14      0.23       975\n",
      "          UP       0.51      0.77      0.61      2411\n",
      "\n",
      "    accuracy                           0.50      6442\n",
      "   macro avg       0.57      0.38      0.40      6442\n",
      "weighted avg       0.54      0.50      0.47      6442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make the CLF object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=9, random_state=123)\n",
    "\n",
    "#Fit the model on the training set \n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = clf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate model performance on training data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.30      0.09      0.14       181\n",
      "        BNSF       0.36      0.39      0.37       748\n",
      "         CSX       0.30      0.14      0.19       339\n",
      "          NS       0.18      0.03      0.06       432\n",
      "          UP       0.44      0.69      0.54      1061\n",
      "\n",
      "    accuracy                           0.40      2761\n",
      "   macro avg       0.32      0.27      0.26      2761\n",
      "weighted avg       0.35      0.40      0.35      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on validate\n",
    "y_pred = clf.predict(X_validate_scaled)\n",
    "\n",
    "# Evaluate model performance on out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "   - Random Forest algorithm achieves a 38% accuracy on validate data set\n",
    "   - The Decision Tree algoithm also performs best at being able to predict the individual railroad companies and this is evident from the precision scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.27      0.14      0.19       126\n",
      "        BNSF       0.39      0.41      0.40       643\n",
      "         CSX       0.35      0.15      0.21       292\n",
      "          NS       0.36      0.08      0.13       367\n",
      "          UP       0.45      0.71      0.55       873\n",
      "\n",
      "    accuracy                           0.42      2301\n",
      "   macro avg       0.37      0.30      0.29      2301\n",
      "weighted avg       0.40      0.42      0.38      2301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict on y\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ATK</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNSF</th>\n",
       "      <td>0.388393</td>\n",
       "      <td>0.405910</td>\n",
       "      <td>0.396958</td>\n",
       "      <td>643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSX</th>\n",
       "      <td>0.352459</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.207729</td>\n",
       "      <td>292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NS</th>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.125843</td>\n",
       "      <td>367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP</th>\n",
       "      <td>0.453412</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.552773</td>\n",
       "      <td>873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.420687</td>\n",
       "      <td>0.420687</td>\n",
       "      <td>0.420687</td>\n",
       "      <td>0.420687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.365193</td>\n",
       "      <td>0.296045</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>2301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.397475</td>\n",
       "      <td>0.420687</td>\n",
       "      <td>0.377349</td>\n",
       "      <td>2301.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "ATK            0.272727  0.142857  0.187500   126.000000\n",
       "BNSF           0.388393  0.405910  0.396958   643.000000\n",
       "CSX            0.352459  0.147260  0.207729   292.000000\n",
       "NS             0.358974  0.076294  0.125843   367.000000\n",
       "UP             0.453412  0.707904  0.552773   873.000000\n",
       "accuracy       0.420687  0.420687  0.420687     0.420687\n",
       "macro avg      0.365193  0.296045  0.294161  2301.000000\n",
       "weighted avg   0.397475  0.420687  0.377349  2301.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equip_rail_class_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T\n",
    "equip_rail_class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "equip_rail_class_report.to_csv('equip_rail_class_report.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Equipment Rail with Different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['railroad_company',\n",
       " 'accident_type',\n",
       " 'state_fips',\n",
       " 'temp',\n",
       " 'visibility',\n",
       " 'weather',\n",
       " 'train_speed',\n",
       " 'train_direction',\n",
       " 'train_weight',\n",
       " 'train_type',\n",
       " 'track_type',\n",
       " 'front_engines',\n",
       " 'loadfrght_cars',\n",
       " 'loadpass_cars',\n",
       " 'emptyfrght_cars',\n",
       " 'emptypass_cars',\n",
       " 'equip_damage',\n",
       " 'track_damage',\n",
       " 'cause',\n",
       " 'total_killed',\n",
       " 'total_injured',\n",
       " 'max_speed',\n",
       " 'total_damage',\n",
       " 'engineers_onduty',\n",
       " 'conductors_onduty',\n",
       " 'brakemen_onduty',\n",
       " 'region',\n",
       " 'typrr',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'signal_type',\n",
       " 'date',\n",
       " 'season',\n",
       " 'state',\n",
       " 'year']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "equip_df = df[['total_killed','total_injured','max_speed','railroad_company', 'track_damage', 'total_damage', 'equip_damage', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = preprocessing.get_object_cols(equip_df)\n",
    "numeric_cols = preprocessing.get_numeric_X_cols(X_train, object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data\n",
    "train, validate, X_train, y_train, X_validate, y_validate, X_test, y_test = preprocessing.train_validate_test(equip_df, 'railroad_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_killed</th>\n",
       "      <th>total_injured</th>\n",
       "      <th>max_speed</th>\n",
       "      <th>railroad_company</th>\n",
       "      <th>track_damage</th>\n",
       "      <th>total_damage</th>\n",
       "      <th>equip_damage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BNSF</td>\n",
       "      <td>21949</td>\n",
       "      <td>22049</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_killed  total_injured  max_speed railroad_company  track_damage  \\\n",
       "8116             0              0          2             BNSF         21949   \n",
       "\n",
       "      total_damage  equip_damage  \n",
       "8116         22049           100  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['weather'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c6bb1eaa57d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-543142eadc7a>\u001b[0m in \u001b[0;36mmin_max_scale\u001b[0;34m(X_train, X_validate, X_test, numeric_cols)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#scale X_train, X_validate, X_test using the mins and maxes stored in the scaler derived from X_train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['weather'] not in index\""
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the scaled data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_scaled)\n",
    "test['predicted'] = lm.predict(X_test_scaled)\n",
    "\n",
    "#Review how the lm model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted, zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the lm model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the KNN object with a k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "\n",
    "#Fit the object to the scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_scaled)\n",
    "\n",
    "#Review how the knn model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted,  zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the knn model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=12, \n",
    "                            random_state=123)\n",
    "\n",
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_scaled)\n",
    "print('----------------')\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the CLF object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=8, random_state=123)\n",
    "\n",
    "#Fit the model on the training set \n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = clf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate model performance on training data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validate\n",
    "y_pred = clf.predict(X_validate_scaled)\n",
    "\n",
    "# Evaluate model performance on out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling After Removing Outliers in Total Damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22402, 146)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aquire the data\n",
    "df = acquire.get_equiprail()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11504, 35)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the data\n",
    "df = prepare.prep_equip_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100, 35)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Outliers from the dataframe\n",
    "df = df[df.total_damage < 234898.75]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10100 entries, 0 to 11503\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   total_damage      10100 non-null  int64 \n",
      " 1   railroad_company  10100 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 236.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Subset the Data Based on Features Selected\n",
    "equip_df = df[['total_damage', 'railroad_company']]\n",
    "equip_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data\n",
    "train, validate, X_train, y_train, X_validate, y_validate, X_test, y_test = preprocessing.train_validate_test(equip_df, 'railroad_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Object and Numeric Columns\n",
    "object_cols = preprocessing.get_object_cols(equip_df)\n",
    "numeric_cols = preprocessing.get_numeric_X_cols(X_train, object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the Data\n",
    "X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 37%\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline Accuracy: {round(max(df.railroad_company.value_counts()) / df.shape[0] *100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       402\n",
      "        BNSF       0.00      0.00      0.00      1547\n",
      "         CSX       0.00      0.00      0.00       737\n",
      "          NS       0.00      0.00      0.00       903\n",
      "          UP       0.37      1.00      0.54      2067\n",
      "\n",
      "    accuracy                           0.37      5656\n",
      "   macro avg       0.07      0.20      0.11      5656\n",
      "weighted avg       0.13      0.37      0.20      5656\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       162\n",
      "        BNSF       0.00      0.00      0.00       592\n",
      "         CSX       0.00      0.00      0.00       325\n",
      "          NS       0.00      0.00      0.00       394\n",
      "          UP       0.39      1.00      0.56       951\n",
      "\n",
      "    accuracy                           0.39      2424\n",
      "   macro avg       0.08      0.20      0.11      2424\n",
      "weighted avg       0.15      0.39      0.22      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the scaled data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_scaled)\n",
    "test['predicted'] = lm.predict(X_test_scaled)\n",
    "\n",
    "#Review how the lm model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted, zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the lm model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       402\n",
      "        BNSF       0.56      0.37      0.45      1547\n",
      "         CSX       0.86      0.02      0.03       737\n",
      "          NS       0.80      0.06      0.11       903\n",
      "          UP       0.43      0.94      0.59      2067\n",
      "\n",
      "    accuracy                           0.46      5656\n",
      "   macro avg       0.53      0.28      0.24      5656\n",
      "weighted avg       0.55      0.46      0.36      5656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "\n",
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       162\n",
      "        BNSF       0.32      0.23      0.27       592\n",
      "         CSX       0.09      0.00      0.01       325\n",
      "          NS       0.32      0.02      0.03       394\n",
      "          UP       0.41      0.84      0.55       951\n",
      "\n",
      "    accuracy                           0.39      2424\n",
      "   macro avg       0.23      0.22      0.17      2424\n",
      "weighted avg       0.30      0.39      0.29      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_scaled)\n",
    "print('----------------')\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "   - Even after removing outliers, the classification models do not make significant imporvements in predicting Railroad involved in an equipment accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
