{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import preprocessing\n",
    "\n",
    "#Visualization Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Sklearn Tools and Modules\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22402, 146)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acquire the Data\n",
    "df = acquire.get_equiprail()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11504, 35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the data\n",
    "df = prepare.prep_equip_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11504 entries, 0 to 11503\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   track_damage      11504 non-null  int64 \n",
      " 1   total_damage      11504 non-null  int64 \n",
      " 2   weather           11504 non-null  int64 \n",
      " 3   equip_damage      11504 non-null  int64 \n",
      " 4   railroad_company  11504 non-null  object\n",
      " 5   year              11504 non-null  int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 629.1+ KB\n"
     ]
    }
   ],
   "source": [
    "equip_df = df[['track_damage', 'total_damage', 'weather', 'equip_damage', 'railroad_company', 'year']]\n",
    "equip_df.info()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data\n",
    "train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test = preprocessing.train_validate_test(equip_df, 'railroad_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6442, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6442,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = preprocessing.get_object_cols(equip_df)\n",
    "numeric_cols = preprocessing.get_numeric_X_cols(X_train, object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled, X_validate_scaled, X_test_scaled = preprocessing.min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(X_train, X_validate, X_test, numeric_cols):\n",
    "    '''\n",
    "    this function takes in 3 dataframes with the same columns, \n",
    "    a list of numeric column names (because the scaler can only work with numeric columns),\n",
    "    and fits a min-max scaler to the first dataframe and transforms all\n",
    "    3 dataframes using that scaler. \n",
    "    it returns 3 dataframes with the same column names and scaled values. \n",
    "    '''\n",
    "    # create the scaler object and fit it to X_train (i.e. identify min and max)\n",
    "    # if copy = false, inplace row normalization happens and avoids a copy (if the input is already a numpy array).\n",
    "\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "    #scale X_train, X_validate, X_test using the mins and maxes stored in the scaler derived from X_train. \n",
    "    # \n",
    "    X_train_scaled_array = scaler.transform(X_train[numeric_cols])\n",
    "    X_validate_scaled_array = scaler.transform(X_validate[numeric_cols])\n",
    "    X_test_scaled_array = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # convert arrays to dataframes\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled_array, \n",
    "                                  columns=numeric_cols).\\\n",
    "                                  set_index([X_train.index.values])\n",
    "\n",
    "    X_validate_scaled = pd.DataFrame(X_validate_scaled_array, \n",
    "                                     columns=numeric_cols).\\\n",
    "                                     set_index([X_validate.index.values])\n",
    "\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled_array, \n",
    "                                 columns=numeric_cols).\\\n",
    "                                 set_index([X_test.index.values])\n",
    "\n",
    "    \n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_damage</th>\n",
       "      <th>total_damage</th>\n",
       "      <th>weather</th>\n",
       "      <th>equip_damage</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10506</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.071481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069471</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10069</th>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6442 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       track_damage  total_damage  weather  equip_damage   year\n",
       "8116       0.003655      0.000850      0.0      0.000004  0.125\n",
       "2539       0.000005      0.002467      0.0      0.002511  0.750\n",
       "10506      0.000033      0.000571      0.2      0.000576  1.000\n",
       "6836       0.013576      0.071481      0.0      0.069471  0.875\n",
       "7873       0.000033      0.001157      0.2      0.001173  0.500\n",
       "...             ...           ...      ...           ...    ...\n",
       "4466       0.001582      0.000807      0.2      0.000451  0.625\n",
       "5250       0.002074      0.000910      0.0      0.000439  0.000\n",
       "9997       0.005115      0.006726      0.2      0.005633  0.000\n",
       "10320      0.000000      0.000887      0.2      0.000905  0.875\n",
       "10069      0.010614      0.008701      0.2      0.006342  0.625\n",
       "\n",
       "[6442 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UP      4345\n",
       "BNSF    3160\n",
       "NS      1774\n",
       "CSX     1482\n",
       "ATK      743\n",
       "Name: railroad_company, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.railroad_company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 38%\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline Accuracy: {round(max(df.railroad_company.value_counts()) / df.shape[0] *100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       436\n",
      "        BNSF       0.68      0.04      0.08      1769\n",
      "         CSX       0.00      0.00      0.00       851\n",
      "          NS       0.00      0.00      0.00       975\n",
      "          UP       0.38      0.99      0.55      2411\n",
      "\n",
      "    accuracy                           0.38      6442\n",
      "   macro avg       0.21      0.21      0.13      6442\n",
      "weighted avg       0.33      0.38      0.23      6442\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.00      0.00      0.00       181\n",
      "        BNSF       0.53      0.03      0.05       748\n",
      "         CSX       0.00      0.00      0.00       339\n",
      "          NS       0.00      0.00      0.00       432\n",
      "          UP       0.38      0.99      0.55      1061\n",
      "\n",
      "    accuracy                           0.39      2761\n",
      "   macro avg       0.18      0.20      0.12      2761\n",
      "weighted avg       0.29      0.39      0.23      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the scaled data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_scaled)\n",
    "test['predicted'] = lm.predict(X_test_scaled)\n",
    "\n",
    "#Review how the lm model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted, zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the lm model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- The LM model does not improve upon the baseline accuracy.\n",
    "- What does this mean for the features we selected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.99      1.00      0.99       436\n",
      "        BNSF       0.99      1.00      1.00      1769\n",
      "         CSX       1.00      1.00      1.00       851\n",
      "          NS       1.00      0.99      0.99       975\n",
      "          UP       1.00      1.00      1.00      2411\n",
      "\n",
      "    accuracy                           1.00      6442\n",
      "   macro avg       1.00      1.00      1.00      6442\n",
      "weighted avg       1.00      1.00      1.00      6442\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.19      0.16      0.17       181\n",
      "        BNSF       0.34      0.34      0.34       748\n",
      "         CSX       0.18      0.15      0.16       339\n",
      "          NS       0.21      0.19      0.20       432\n",
      "          UP       0.43      0.48      0.45      1061\n",
      "\n",
      "    accuracy                           0.34      2761\n",
      "   macro avg       0.27      0.26      0.27      2761\n",
      "weighted avg       0.33      0.34      0.33      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the KNN object with a k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
    "\n",
    "#Fit the object to the scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_scaled)\n",
    "\n",
    "#Review how the knn model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted,  zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the knn model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "   - Using a K=6 returns the best accuracy score for predicting railroad company\n",
    "   - Using weights=distance parameter results in overfitting on the train dataset but retains a similar accuracy score on the validate data as the default weights hyperparamter of 'uniform'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.70      0.38      0.49       436\n",
      "        BNSF       0.62      0.68      0.65      1769\n",
      "         CSX       0.80      0.33      0.47       851\n",
      "          NS       0.84      0.24      0.37       975\n",
      "          UP       0.60      0.90      0.72      2411\n",
      "\n",
      "    accuracy                           0.63      6442\n",
      "   macro avg       0.71      0.51      0.54      6442\n",
      "weighted avg       0.67      0.63      0.60      6442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "\n",
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.33      0.14      0.20       181\n",
      "        BNSF       0.39      0.41      0.40       748\n",
      "         CSX       0.42      0.13      0.20       339\n",
      "          NS       0.28      0.06      0.09       432\n",
      "          UP       0.45      0.72      0.55      1061\n",
      "\n",
      "    accuracy                           0.42      2761\n",
      "   macro avg       0.37      0.29      0.29      2761\n",
      "weighted avg       0.39      0.42      0.37      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_scaled)\n",
    "print('----------------')\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "   - Random Forest achieves the highest accuracy score thus far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.59      0.31      0.41       436\n",
      "        BNSF       0.47      0.57      0.52      1769\n",
      "         CSX       0.54      0.33      0.40       851\n",
      "          NS       0.64      0.16      0.26       975\n",
      "          UP       0.53      0.73      0.61      2411\n",
      "\n",
      "    accuracy                           0.52      6442\n",
      "   macro avg       0.55      0.42      0.44      6442\n",
      "weighted avg       0.53      0.52      0.49      6442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make the CLF object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=9, random_state=123)\n",
    "\n",
    "#Fit the model on the training set \n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = clf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate model performance on training data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.24      0.12      0.16       181\n",
      "        BNSF       0.35      0.42      0.38       748\n",
      "         CSX       0.29      0.17      0.22       339\n",
      "          NS       0.18      0.04      0.07       432\n",
      "          UP       0.44      0.61      0.51      1061\n",
      "\n",
      "    accuracy                           0.38      2761\n",
      "   macro avg       0.30      0.27      0.27      2761\n",
      "weighted avg       0.34      0.38      0.35      2761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on validate\n",
    "y_pred = clf.predict(X_validate_scaled)\n",
    "\n",
    "# Evaluate model performance on out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "   - Random Forest algorithm achieves a 42% accuracy on validate data set\n",
    "   - The Decision Tree algoithm also performs best at being able to predict the individual railroad companies and this is evident from the precision scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ATK       0.31      0.17      0.22       126\n",
      "        BNSF       0.36      0.36      0.36       643\n",
      "         CSX       0.38      0.14      0.21       292\n",
      "          NS       0.38      0.08      0.13       367\n",
      "          UP       0.44      0.71      0.55       873\n",
      "\n",
      "    accuracy                           0.41      2301\n",
      "   macro avg       0.37      0.29      0.29      2301\n",
      "weighted avg       0.39      0.41      0.37      2301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict on y\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
