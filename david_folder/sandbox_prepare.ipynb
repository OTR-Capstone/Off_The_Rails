{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep & Explore Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from acquire import get_hwyrail, get_equiprail\n",
    "from prepare import missing_zero_values_table, max_reduce_equip_cols, concat_date_time, prep_equip_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf = get_hwyrail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_zero_values_table(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "equipdf = get_equiprail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "equipdf = prep_equip_df(equipdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "equipdf.columns.to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "railroad_company, accident_type, state, temp, visibility, weather, train_speed, train_direction, train_weight, train_type, track_type, front_engines, loadfrght_cars, loadpass_cars, emptyfrght_cars, emptypass_cars, equip_damage, track_damage, cause, caskldrr, casinjrr, total_killed, total_injured, max_speed, total_damage, engineers_onduty, conductors_onduty, brakemen_onduty, region, typrr, rremp_killed, rremp_injured, passengers_killed, passengers_injured, passtrn, lat, long, signal_type, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "equipdf.columns = ['railroad_company', \n",
    "                   'accident_type', \n",
    "                   'state', \n",
    "                   'temp', \n",
    "                   'visibility',\n",
    "                   'weather', \n",
    "                   'train_speed', \n",
    "                   'train_direction',\n",
    "                   'train_weight', \n",
    "                   'train_type',\n",
    "                   'track_type', \n",
    "                   'front_engines', \n",
    "                   'loadfrght_cars',\n",
    "                   'loadpass_cars', \n",
    "                   'emptyfrght_cars',\n",
    "                   'emptypass_cars', \n",
    "                   'equip_damage',\n",
    "                   'track_damage', \n",
    "                   'cause',\n",
    "                   'caskldrr',\n",
    "                   'casinjrr', \n",
    "                   'total_killed', \n",
    "                   'total_injured', \n",
    "                   'max_speed', \n",
    "                   'total_damage', \n",
    "                   'engineers_onduty',\n",
    "                   'conductors_onduty', \n",
    "                   'brakemen_onduty', \n",
    "                   'region', \n",
    "                   'typrr', \n",
    "                   'rremp_killed',\n",
    "                   'rremp_injured',\n",
    "                   'passengers_killed',\n",
    "                   'passengers_injured',\n",
    "                   'passtrn', \n",
    "                   'lat', \n",
    "                   'long', \n",
    "                   'signal_type',\n",
    "                   'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['AMTRAK','RAILROAD','INCDTNO','YEAR','MONTH','DAY','TIMEHR','TIMEMIN','AMPM','STATION','COUNTY','STATE','REGION','CITY',\n",
    " 'VEHSPD','TYPVEH','VEHDIR','POSITION','TYPACC','HAZARD','TEMP','VISIBLTY','WEATHER','TYPEQ','TYPTRK','NBRLOCOS','NBRCARS',\n",
    " 'TRNSPD','TRNDIR','LOCWARN','WARNSIG','LIGHTS','STANDVEH','TRAIN2','MOTORIST','VIEW','VEHDMG','DRIVER','INVEH','TOTKLD',\n",
    " 'TOTINJ','TOTOCC','CASKLDRR','PUBLIC','CNTYCD','STCNTY','HZMRLSED','HZMNAME','HZMQNTY','WHISBAN','DRIVAGE','DRIVGEN',\n",
    " 'PLEONTRN','USERKLD','USERINJ','RREMPKLD','RREMPINJ','PASSKLD','PASSINJ','ROADCOND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_reduce_hwy_cols(df):\n",
    "    '''\n",
    "    This function takes in the hwy/rail data frame and drops columns:\n",
    "        - With 80% of null values\n",
    "        - Features not inlcuded in this analyis\n",
    "        - Duplicated information columns\n",
    "\n",
    "    It returns a single dataframe\n",
    "    '''\n",
    "    #Define threshold\n",
    "    threshold = len(df) * 0.80\n",
    "    \n",
    "    #Drop cols with 80% or more missing values\n",
    "    df = df.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "    df = df[['RAILROAD','INCDTNO','YEAR','MONTH','DAY','TIMEHR','TIMEMIN','AMPM','STATION','COUNTY','STATE','REGION','CITY',\n",
    " 'VEHSPD','TYPVEH','VEHDIR','POSITION','TYPACC','HAZARD','TEMP','VISIBLTY','WEATHER','TYPEQ','TYPTRK','NBRLOCOS','NBRCARS',\n",
    " 'TRNSPD','TRNDIR','LOCWARN','WARNSIG','LIGHTS','STANDVEH','TRAIN2','MOTORIST','VIEW','VEHDMG','DRIVER','INVEH','TOTKLD',\n",
    " 'TOTINJ','TOTOCC','PUBLIC','CNTYCD','WHISBAN','DRIVAGE','DRIVGEN',\n",
    " 'PLEONTRN','USERKLD','USERINJ','RREMPKLD','RREMPINJ','PASSKLD','PASSINJ','ROADCOND']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf = min_reduce_hwy_cols(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_zero_values_table(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_reduce_hwy_cols(df):\n",
    "    '''\n",
    "    This function takes in the equipemnet rail data frame and drops collumns:\n",
    "        - With 60% of null values\n",
    "        - Features not inlcuded in this analyis\n",
    "        - Duplicated information columns\n",
    "\n",
    "    It returns a single dataframe\n",
    "    '''\n",
    "    #Define threshold\n",
    "    threshold = len(df) * 0.60\n",
    "    \n",
    "    #Drop cols with 80% or more missing values\n",
    "    df = df.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "    df = df[['RAILROAD','INCDTNO','YEAR','MONTH','DAY','TIMEHR','TIMEMIN','AMPM','STATION','COUNTY','STATE','REGION','CITY',\n",
    " 'VEHSPD','TYPVEH','VEHDIR','POSITION','TYPACC','HAZARD','TEMP','VISIBLTY','WEATHER','TYPEQ','TYPTRK','NBRLOCOS','NBRCARS',\n",
    " 'TRNSPD','TRNDIR','LOCWARN','WARNSIG','LIGHTS','STANDVEH','TRAIN2','MOTORIST','VIEW','VEHDMG','DRIVER','INVEH','TOTKLD',\n",
    " 'TOTINJ','TOTOCC','PUBLIC','CNTYCD','WHISBAN','DRIVAGE','DRIVGEN',\n",
    " 'PLEONTRN','USERKLD','USERINJ','RREMPKLD','RREMPINJ','PASSKLD','PASSINJ','ROADCOND']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf = max_reduce_hwy_cols(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_date_time(df):\n",
    "    '''\n",
    "    This function takes in the equip rail data frame and:\n",
    "    - Concatenates the date time values as a datetime object\n",
    "    - Drops the original columns for date and time\n",
    "        \n",
    "    It returns a single dataframe\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Concatenate datetime columns\n",
    "    df['date'] = pd.to_datetime(df.MONTH.astype(str)+' '+df.DAY.astype(str)+' '+df.YEAR.astype(str)+' '+df.TIMEHR.astype(str)+':'+df.TIMEMIN.astype(str)+' '+df.AMPM.astype(str))\n",
    "    \n",
    "    #Drop original date time columns\n",
    "    df.drop(columns={'YEAR', 'MONTH', 'DAY', 'TIMEHR', 'TIMEMIN', 'AMPM'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf = concat_date_time(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_hwy_clean(df):\n",
    "    '''\n",
    "    This function takes in the equip df and prepares it for analysis by:\n",
    "        - lowercasing all column titles\n",
    "        - convert lat and long to string dtypes\n",
    "        -\n",
    "\n",
    "    It returns a single dataframe\n",
    "        \n",
    "    '''\n",
    "    #lowecase all column titles\n",
    "    df.columns= df.columns.str.lower()\n",
    "\n",
    "    #Drop null values\n",
    "    #drop null values\n",
    "    df = df.dropna(axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf = general_hwy_clean(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hwy_index(df):\n",
    "    '''\n",
    "    This function takes in the equipment dataframe and sets the index\n",
    "    to the unique incident number after first dropping the observations\n",
    "    with duplicate incident numbers\n",
    "    '''\n",
    "\n",
    "    #Filters out observations with unique incident numbers \n",
    "    counts = df['incdtno'].value_counts()\n",
    "    df = df[~df['incdtno'].isin(counts[counts > 1].index)]\n",
    "\n",
    "    #set the index\n",
    "    df.set_index('incdtno', drop=True, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf = set_hwy_index(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_hwy_columns(df):\n",
    "    \n",
    "    '''\n",
    "    This function will rename the columns. Only run after max_reduce, concat_date_time, general_equip_clean,\n",
    "    and set_equip_index\n",
    "    \n",
    "    '''  \n",
    "    \n",
    "    #rename columns\n",
    "    \n",
    "    df.columns = ['railroad_company',\n",
    "                  'station',\n",
    "                  'county',\n",
    "                  'state',\n",
    "                  'region',\n",
    "                  'city',\n",
    "                  'vehicle_speed',\n",
    "                  'vehicle_type',\n",
    "                  'vehicle_direction',\n",
    "                  'position',\n",
    "                  'accident_type',\n",
    "                  'hazmat_entity',\n",
    "                  'temp',\n",
    "                  'visibility',\n",
    "                  'weather',\n",
    "                  'train_type',\n",
    "                  'track_type',\n",
    "                  'front_engines',\n",
    "                  'railcar_quantity',\n",
    "                  'train_speed',\n",
    "                  'train_direction',\n",
    "                  'warning_location',\n",
    "                  'warning_signal',\n",
    "                  'lights',\n",
    "                  'standveh',\n",
    "                  'other_train',\n",
    "                  'motorist_action',\n",
    "                  'view_obstruction',\n",
    "                  'vehicle_damage',\n",
    "                  'driver_fate',\n",
    "                  'vehicle_occupied',\n",
    "                  'total_killed',\n",
    "                  'total_injured',\n",
    "                  'vehicle_occupants',\n",
    "                  'ispublic_crossing',\n",
    "                  'fips',\n",
    "                  'whistle_ban',\n",
    "                  'driver_age',\n",
    "                  'driver_gender',\n",
    "                  'train_occupants',\n",
    "                  'user_killed',\n",
    "                  'user_injured',\n",
    "                  'rail_killed',\n",
    "                  'rail_injured',\n",
    "                  'train_pass_killed',\n",
    "                  'train_pass_injured',\n",
    "                  'road_condtions',\n",
    "                  'date']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_hwy_df(df):\n",
    "    '''\n",
    "    This function takes in the equipment rail data frame\n",
    "    and applies the prepare and cleaning functions to it so that it is ready\n",
    "    for analysis.\n",
    "\n",
    "    It returns a single dataframe\n",
    "    '''\n",
    "\n",
    "    #Reduce columns\n",
    "    df = max_reduce_hwy_cols(df)\n",
    "\n",
    "    #Deal with date time columsn\n",
    "    df = concat_date_time(df)\n",
    "\n",
    "    #general cleaning\n",
    "    df = general_hwy_clean(df)\n",
    "\n",
    "    #set the index\n",
    "    df = set_hwy_index(df)\n",
    "\n",
    "    #rename columns\n",
    "    df = rename_hwy_columns(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf = prep_hwy_df(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16521, 48)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwydf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['railroad_company','station','county','state','region','city',\n",
    " 'vehicle_speed','vehicle_type','vehicle_direction','position','accident_type','hazmat_entity','temp','visibility','weather','train_type','track_type',\n",
    " 'front_engines','railcar_quantity','train_speed','train_direction','warning_location','warning_signal','lights','standveh','other_train','motorist_action',\n",
    " 'view_obstruction','vehicle_damage','driver_fate','vehicle_occupied','total_killed','total_injured','vehicle_occupants', 'ispublic_crossing','fips','whistle_ban',\n",
    " 'driver_age','driver_gender','train_occupants','user_killed','user_injured','rail_killed','rail_injured','train_pass_killed','train_pass_injured','road_condtions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwydf.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
