{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from acquire import get_hwyrail, get_equiprail\n",
    "from prepare import prep_hwy_df, prep_equip_df\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import date, datetime\n",
    "from explore import train_validate_test_split, freq_table\n",
    "\n",
    "\n",
    "# modeling methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "\n",
    "from preprocessing import get_object_cols, get_numeric_X_cols, train_validate_test, min_max_scale, get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_hwyrail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_hwy_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12181 entries, 0 to 12180\n",
      "Data columns (total 55 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   railroad_company    12181 non-null  object        \n",
      " 1   station             12181 non-null  object        \n",
      " 2   county              12181 non-null  object        \n",
      " 3   state_fips          12181 non-null  int64         \n",
      " 4   region              12181 non-null  int64         \n",
      " 5   city                12181 non-null  object        \n",
      " 6   vehicle_speed       12181 non-null  float64       \n",
      " 7   vehicle_type        12181 non-null  object        \n",
      " 8   vehicle_direction   12181 non-null  object        \n",
      " 9   position            12181 non-null  object        \n",
      " 10  accident_type       12181 non-null  int64         \n",
      " 11  hazmat_entity       12181 non-null  object        \n",
      " 12  temp                12181 non-null  int64         \n",
      " 13  visibility          12181 non-null  int64         \n",
      " 14  weather             12181 non-null  object        \n",
      " 15  train_type          12181 non-null  object        \n",
      " 16  track_type          12181 non-null  object        \n",
      " 17  front_engines       12181 non-null  int64         \n",
      " 18  railcar_quantity    12181 non-null  int64         \n",
      " 19  train_speed         12181 non-null  float64       \n",
      " 20  train_direction     12181 non-null  object        \n",
      " 21  warning_location    12181 non-null  object        \n",
      " 22  warning_signal      12181 non-null  object        \n",
      " 23  lights              12181 non-null  object        \n",
      " 24  standveh            12181 non-null  object        \n",
      " 25  other_train         12181 non-null  object        \n",
      " 26  motorist_action     12181 non-null  object        \n",
      " 27  view_obstruction    12181 non-null  int64         \n",
      " 28  vehicle_damage      12181 non-null  float64       \n",
      " 29  driver_fate         12181 non-null  object        \n",
      " 30  vehicle_occupied    12181 non-null  object        \n",
      " 31  total_killed        12181 non-null  int64         \n",
      " 32  total_injured       12181 non-null  int64         \n",
      " 33  vehicle_occupants   12181 non-null  int64         \n",
      " 34  ispublic_crossing   12181 non-null  object        \n",
      " 35  fips                12181 non-null  int64         \n",
      " 36  whistle_ban         12181 non-null  object        \n",
      " 37  driver_age          12181 non-null  object        \n",
      " 38  driver_gender       12181 non-null  object        \n",
      " 39  train_occupants     12181 non-null  int64         \n",
      " 40  user_killed         12181 non-null  int64         \n",
      " 41  user_injured        12181 non-null  int64         \n",
      " 42  rail_killed         12181 non-null  int64         \n",
      " 43  rail_injured        12181 non-null  int64         \n",
      " 44  train_pass_killed   12181 non-null  int64         \n",
      " 45  train_pass_injured  12181 non-null  int64         \n",
      " 46  road_condtions      12181 non-null  object        \n",
      " 47  date                12181 non-null  datetime64[ns]\n",
      " 48  state               12181 non-null  object        \n",
      " 49  state_region        12181 non-null  object        \n",
      " 50  year                12181 non-null  int64         \n",
      " 51  Fall                12181 non-null  uint8         \n",
      " 52  Spring              12181 non-null  uint8         \n",
      " 53  Summer              12181 non-null  uint8         \n",
      " 54  Winter              12181 non-null  uint8         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(20), object(27), uint8(4)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12181 entries, 0 to 12180\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   railroad_company  12181 non-null  object \n",
      " 1   fips              12181 non-null  int64  \n",
      " 2   railcar_quantity  12181 non-null  int64  \n",
      " 3   vehicle_damage    12181 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 475.8+ KB\n"
     ]
    }
   ],
   "source": [
    "hwydf = df[['railroad_company', 'fips', 'railcar_quantity', 'vehicle_damage' ]]\n",
    "hwydf.info()   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hwydf.weather = pd.to_numeric(hwydf.weather, errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hwydf.lights = pd.to_numeric(hwydf.lights, errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hwydf.driver_fate = pd.to_numeric(hwydf.driver_fate, errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, X_train, y_train, X_validate, y_validate, X_test, y_test = train_validate_test(hwydf, 'railroad_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6820, 3), (2924, 3), (2437, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = get_object_cols(hwydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = get_numeric_X_cols(X_train, object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>railcar_quantity</th>\n",
       "      <th>vehicle_damage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>0.290363</td>\n",
       "      <td>0.342776</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.410765</td>\n",
       "      <td>0.008667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.246459</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>0.195244</td>\n",
       "      <td>0.110482</td>\n",
       "      <td>0.002267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.035044</td>\n",
       "      <td>0.169972</td>\n",
       "      <td>0.002667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>0.122653</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>0.120150</td>\n",
       "      <td>0.147309</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>0.165207</td>\n",
       "      <td>0.260623</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.161473</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0.090113</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6820 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fips  railcar_quantity  vehicle_damage\n",
       "2108  0.290363          0.342776        0.001333\n",
       "1914  0.145181          0.410765        0.008667\n",
       "6197  0.002503          0.246459        0.015467\n",
       "7030  0.195244          0.110482        0.002267\n",
       "420   0.035044          0.169972        0.002667\n",
       "...        ...               ...             ...\n",
       "9383  0.122653          0.025496        0.001333\n",
       "2434  0.120150          0.147309        0.004000\n",
       "6351  0.165207          0.260623        0.020000\n",
       "3450  0.042553          0.161473        0.013333\n",
       "1650  0.090113          0.002833        0.020000\n",
       "\n",
       "[6820 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UP      2959\n",
       "CSX     2825\n",
       "NS      2715\n",
       "BNSF    2274\n",
       "ATK      956\n",
       "KCS      452\n",
       "Name: railroad_company, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.railroad_company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 24%\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline Accuracy: {round(max(df.railroad_company.value_counts()) / df.shape[0] *100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.02      0.01      0.01       536\n",
      "        BNSF       0.00      0.00      0.00      1246\n",
      "        CSX        0.24      0.11      0.15      1553\n",
      "        KCS        0.00      0.00      0.00       251\n",
      "        NS         0.26      0.45      0.33      1513\n",
      "        UP         0.32      0.62      0.42      1721\n",
      "\n",
      "    accuracy                           0.28      6820\n",
      "   macro avg       0.14      0.20      0.15      6820\n",
      "weighted avg       0.20      0.28      0.22      6820\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.05      0.01      0.02       241\n",
      "        BNSF       0.00      0.00      0.00       567\n",
      "        CSX        0.27      0.13      0.18       705\n",
      "        KCS        0.00      0.00      0.00       104\n",
      "        NS         0.26      0.47      0.33       647\n",
      "        UP         0.29      0.61      0.40       660\n",
      "\n",
      "    accuracy                           0.27      2924\n",
      "   macro avg       0.15      0.20      0.16      2924\n",
      "weighted avg       0.19      0.27      0.21      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the scaled data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_scaled)\n",
    "test['predicted'] = lm.predict(X_test_scaled)\n",
    "\n",
    "#Review how the lm model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted, zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the lm model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## KNN\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.97      1.00      0.99       536\n",
      "        BNSF       0.97      1.00      0.99      1246\n",
      "        CSX        0.99      0.99      0.99      1553\n",
      "        KCS        0.99      0.99      0.99       251\n",
      "        NS         0.99      0.98      0.99      1513\n",
      "        UP         1.00      0.98      0.99      1721\n",
      "\n",
      "    accuracy                           0.99      6820\n",
      "   macro avg       0.99      0.99      0.99      6820\n",
      "weighted avg       0.99      0.99      0.99      6820\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.58      0.68      0.63       241\n",
      "        BNSF       0.40      0.40      0.40       567\n",
      "        CSX        0.41      0.41      0.41       705\n",
      "        KCS        0.09      0.03      0.04       104\n",
      "        NS         0.33      0.30      0.31       647\n",
      "        UP         0.41      0.46      0.43       660\n",
      "\n",
      "    accuracy                           0.40      2924\n",
      "   macro avg       0.37      0.38      0.37      2924\n",
      "weighted avg       0.39      0.40      0.40      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the KNN object with a k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "#Fit the object to the scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_scaled)\n",
    "\n",
    "#Review how the knn model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted,  zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the knn model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.67      0.89      0.77       536\n",
      "        BNSF       0.70      0.76      0.73      1246\n",
      "        CSX        0.90      0.69      0.78      1553\n",
      "        KCS        0.95      0.08      0.15       251\n",
      "        NS         0.59      0.67      0.63      1513\n",
      "        UP         0.67      0.72      0.69      1721\n",
      "\n",
      "    accuracy                           0.70      6820\n",
      "   macro avg       0.75      0.64      0.63      6820\n",
      "weighted avg       0.72      0.70      0.69      6820\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.58      0.79      0.67       241\n",
      "        BNSF       0.62      0.66      0.64       567\n",
      "        CSX        0.79      0.58      0.67       705\n",
      "        KCS        0.00      0.00      0.00       104\n",
      "        NS         0.49      0.53      0.51       647\n",
      "        UP         0.51      0.60      0.55       660\n",
      "\n",
      "    accuracy                           0.59      2924\n",
      "   macro avg       0.50      0.53      0.51      2924\n",
      "weighted avg       0.58      0.59      0.58      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "\n",
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate on train\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "\n",
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_scaled)\n",
    "print('----------------')\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.45      0.95      0.61       536\n",
      "        BNSF       0.63      0.65      0.64      1246\n",
      "        CSX        0.89      0.48      0.62      1553\n",
      "        KCS        0.00      0.00      0.00       251\n",
      "        NS         0.41      0.52      0.45      1513\n",
      "        UP         0.49      0.46      0.48      1721\n",
      "\n",
      "    accuracy                           0.53      6820\n",
      "   macro avg       0.48      0.51      0.47      6820\n",
      "weighted avg       0.57      0.53      0.53      6820\n",
      "\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.45      0.92      0.60       241\n",
      "        BNSF       0.63      0.64      0.64       567\n",
      "        CSX        0.88      0.47      0.61       705\n",
      "        KCS        0.00      0.00      0.00       104\n",
      "        NS         0.41      0.53      0.46       647\n",
      "        UP         0.48      0.46      0.47       660\n",
      "\n",
      "    accuracy                           0.53      2924\n",
      "   macro avg       0.47      0.50      0.46      2924\n",
      "weighted avg       0.57      0.53      0.53      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make the CLF object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, random_state=123)\n",
    "\n",
    "#Fit the model on the training set \n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = clf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate model performance on training data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "# Predict on validate\n",
    "y_pred = clf.predict(X_validate_scaled)\n",
    "\n",
    "# Evaluate model performance on out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.59      0.83      0.69       179\n",
      "        BNSF       0.63      0.70      0.67       461\n",
      "        CSX        0.80      0.60      0.69       567\n",
      "        KCS        0.33      0.01      0.02        97\n",
      "        NS         0.47      0.53      0.49       555\n",
      "        UP         0.50      0.54      0.52       578\n",
      "\n",
      "    accuracy                           0.58      2437\n",
      "   macro avg       0.55      0.54      0.51      2437\n",
      "weighted avg       0.59      0.58      0.57      2437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict on y\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
