{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import preprocessing\n",
    "\n",
    "#Visualization Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Sklearn Tools and Modules\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18995, 104)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acquire the Data\n",
    "df = acquire.get_hwyrail()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12181, 49)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the data\n",
    "df = prepare.prep_hwy_df(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12181 entries, 0312RS009 to 193825\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   temp              12181 non-null  int64  \n",
      " 1   total_killed      12181 non-null  int64  \n",
      " 2   railcar_quantity  12181 non-null  int64  \n",
      " 3   vehicle_speed     12181 non-null  float64\n",
      " 4   railroad_company  12181 non-null  object \n",
      " 5   driver_gender     12181 non-null  object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 666.1+ KB\n"
     ]
    }
   ],
   "source": [
    "hwy_df = df[['temp', 'total_killed', 'railcar_quantity', 'vehicle_speed', 'railroad_company', 'driver_gender']]\n",
    "hwy_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data\n",
    "train, validate, X_train, y_train, X_validate, y_validate, X_test, y_test = preprocessing.train_validate_test(hwy_df, 'railroad_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6820, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6820,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2924, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = preprocessing.get_object_cols(hwy_df)\n",
    "numeric_cols = preprocessing.get_numeric_X_cols(X_train, object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(X_train, X_validate, X_test, numeric_cols):\n",
    "    '''\n",
    "    this function takes in 3 dataframes with the same columns, \n",
    "    a list of numeric column names (because the scaler can only work with numeric columns),\n",
    "    and fits a min-max scaler to the first dataframe and transforms all\n",
    "    3 dataframes using that scaler. \n",
    "    it returns 3 dataframes with the same column names and scaled values. \n",
    "    '''\n",
    "    # create the scaler object and fit it to X_train (i.e. identify min and max)\n",
    "    # if copy = false, inplace row normalization happens and avoids a copy (if the input is already a numpy array).\n",
    "\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "    #scale X_train, X_validate, X_test using the mins and maxes stored in the scaler derived from X_train. \n",
    "    # \n",
    "    X_train_scaled_array = scaler.transform(X_train[numeric_cols])\n",
    "    X_validate_scaled_array = scaler.transform(X_validate[numeric_cols])\n",
    "    X_test_scaled_array = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # convert arrays to dataframes\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled_array, \n",
    "                                  columns=numeric_cols).\\\n",
    "                                  set_index([X_train.index.values])\n",
    "\n",
    "    X_validate_scaled = pd.DataFrame(X_validate_scaled_array, \n",
    "                                     columns=numeric_cols).\\\n",
    "                                     set_index([X_validate.index.values])\n",
    "\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled_array, \n",
    "                                 columns=numeric_cols).\\\n",
    "                                 set_index([X_test.index.values])\n",
    "\n",
    "    \n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>total_killed</th>\n",
       "      <th>railcar_quantity</th>\n",
       "      <th>vehicle_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1113FW028</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX0813202</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0316SA020</th>\n",
       "      <td>0.719697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0217LK004</th>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138810</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97867</th>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511</th>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.247525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS0513202</th>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.283286</td>\n",
       "      <td>0.099010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE0716200</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382436</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014PD018</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0513CB002</th>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297450</td>\n",
       "      <td>0.198020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6820 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               temp  total_killed  railcar_quantity  vehicle_speed\n",
       "1113FW028  0.636364           0.0          0.000000       0.049505\n",
       "TX0813202  0.757576           0.0          0.181303       0.000000\n",
       "0316SA020  0.719697           0.0          0.000000       0.297030\n",
       "0217LK004  0.606061           0.0          0.138810       0.000000\n",
       "97867      0.492424           0.0          0.025496       0.000000\n",
       "...             ...           ...               ...            ...\n",
       "155511     0.878788           0.0          0.019830       0.247525\n",
       "KS0513202  0.628788           0.2          0.283286       0.099010\n",
       "NE0716200  0.909091           0.0          0.382436       0.049505\n",
       "1014PD018  0.583333           0.0          0.308782       0.000000\n",
       "0513CB002  0.507576           0.0          0.297450       0.198020\n",
       "\n",
       "[6820 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UP      2959\n",
       "CSX     2825\n",
       "NS      2715\n",
       "BNSF    2274\n",
       "ATK      956\n",
       "KCS      452\n",
       "Name: railroad_company, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.railroad_company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 24%\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline Accuracy: {round(max(df.railroad_company.value_counts()) / df.shape[0] *100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.37      0.25      0.29       541\n",
      "        BNSF       0.33      0.11      0.17      1310\n",
      "        CSX        0.30      0.12      0.17      1537\n",
      "        KCS        0.00      0.00      0.00       257\n",
      "        NS         0.32      0.55      0.40      1525\n",
      "        UP         0.32      0.53      0.40      1650\n",
      "\n",
      "    accuracy                           0.32      6820\n",
      "   macro avg       0.27      0.26      0.24      6820\n",
      "weighted avg       0.31      0.32      0.28      6820\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.38      0.26      0.31       233\n",
      "        BNSF       0.26      0.10      0.14       518\n",
      "        CSX        0.29      0.10      0.15       700\n",
      "        KCS        0.00      0.00      0.00       111\n",
      "        NS         0.29      0.53      0.38       645\n",
      "        UP         0.32      0.52      0.39       717\n",
      "\n",
      "    accuracy                           0.31      2924\n",
      "   macro avg       0.26      0.25      0.23      2924\n",
      "weighted avg       0.29      0.31      0.27      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the scaled data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_scaled)\n",
    "test['predicted'] = lm.predict(X_test_scaled)\n",
    "\n",
    "#Review how the lm model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted, zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the lm model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "- My LR model beat my baseline (.24) by .16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.69      0.82      0.75       541\n",
      "        BNSF       0.54      0.29      0.38      1310\n",
      "        CSX        0.41      0.40      0.41      1537\n",
      "        KCS        0.74      0.13      0.22       257\n",
      "        NS         0.46      0.54      0.49      1525\n",
      "        UP         0.41      0.53      0.46      1650\n",
      "\n",
      "    accuracy                           0.46      6820\n",
      "   macro avg       0.54      0.45      0.45      6820\n",
      "weighted avg       0.48      0.46      0.45      6820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make the CLF object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=9, random_state=123)\n",
    "\n",
    "#Fit the model on the training set \n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = clf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate model performance on training data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.66      0.85      0.74       233\n",
      "        BNSF       0.28      0.16      0.21       518\n",
      "        CSX        0.34      0.30      0.32       700\n",
      "        KCS        0.11      0.02      0.03       111\n",
      "        NS         0.37      0.43      0.40       645\n",
      "        UP         0.35      0.45      0.39       717\n",
      "\n",
      "    accuracy                           0.38      2924\n",
      "   macro avg       0.35      0.37      0.35      2924\n",
      "weighted avg       0.35      0.38      0.36      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on validate\n",
    "y_pred = clf.predict(X_validate_scaled)\n",
    "\n",
    "# Evaluate model performance on out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "- My dt model performed quite well on all railroads, UP was 46%\n",
    "- On validate, the perfomance dropped to 39%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.66      0.88      0.76       541\n",
      "        BNSF       0.65      0.42      0.51      1310\n",
      "        CSX        0.56      0.48      0.52      1537\n",
      "        KCS        1.00      0.07      0.13       257\n",
      "        NS         0.51      0.65      0.57      1525\n",
      "        UP         0.51      0.62      0.56      1650\n",
      "\n",
      "    accuracy                           0.55      6820\n",
      "   macro avg       0.65      0.52      0.51      6820\n",
      "weighted avg       0.58      0.55      0.54      6820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "\n",
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "#Evaluate\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.62      0.88      0.73       233\n",
      "        BNSF       0.36      0.23      0.28       518\n",
      "        CSX        0.37      0.28      0.32       700\n",
      "        KCS        0.00      0.00      0.00       111\n",
      "        NS         0.39      0.51      0.44       645\n",
      "        UP         0.35      0.43      0.38       717\n",
      "\n",
      "    accuracy                           0.40      2924\n",
      "   macro avg       0.35      0.39      0.36      2924\n",
      "weighted avg       0.37      0.40      0.38      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_scaled)\n",
    "\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(y_validate, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "- Rf performed well on train data at 56%, but dropped off 38% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.90      0.99      0.95       541\n",
      "        BNSF       0.90      0.98      0.94      1310\n",
      "        CSX        0.93      0.95      0.94      1537\n",
      "        KCS        0.93      0.92      0.93       257\n",
      "        NS         0.96      0.92      0.94      1525\n",
      "        UP         0.99      0.90      0.94      1650\n",
      "\n",
      "    accuracy                           0.94      6820\n",
      "   macro avg       0.93      0.94      0.94      6820\n",
      "weighted avg       0.94      0.94      0.94      6820\n",
      "\n",
      "----------------\n",
      "Out-of-sample data model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ATK        0.55      0.75      0.63       233\n",
      "        BNSF       0.25      0.27      0.26       518\n",
      "        CSX        0.29      0.27      0.28       700\n",
      "        KCS        0.09      0.05      0.07       111\n",
      "        NS         0.34      0.34      0.34       645\n",
      "        UP         0.30      0.29      0.30       717\n",
      "\n",
      "    accuracy                           0.32      2924\n",
      "   macro avg       0.30      0.33      0.31      2924\n",
      "weighted avg       0.31      0.32      0.31      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the KNN object with a k = 6\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "#Fit the object to the scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Create corresponding dataframes \n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_scaled)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_scaled)\n",
    "\n",
    "#Review how the knn model performed on the in-sample data\n",
    "print('In-sample data model performance:')\n",
    "print(classification_report(train.actual, train.predicted,  zero_division=0))\n",
    "print('----------------')\n",
    "#Review how the knn model performed on the out-of-sample data\n",
    "print('Out-of-sample data model performance:')\n",
    "print(classification_report(validate.actual, validate.predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "- No matter the n_neighbor value, the training data performed exceptionally well and the validate data dropped dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
